{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY8z4UO5lrGB"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "## Table of Contents\n",
        "1. [Dataset Overview](#dataset-overview)\n",
        "2. [Handling Missing Values](#handling-missing-values)\n",
        "3. [Feature Distributions](#feature-distributions)\n",
        "4. [Possible Biases](#possible-biases)\n",
        "5. [Feature Selection and Correlation Analysis](#correlations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srHznX5SlrGD"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "%pip install ucimlrepo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OftNOC-alrGE"
      },
      "source": [
        "## Dataset Overview\n",
        "\n",
        "[Provide a high-level overview of the dataset. This should include the source of the dataset, the number of samples, the number of features, and example showing the structure of the dataset.]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GpG8aW-lrGE"
      },
      "source": [
        "### Attention: currently commented out since there is better way as shown in the next code snippet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vCxzauRlrGE"
      },
      "outputs": [],
      "source": [
        "# comment out the following lines\n",
        "\n",
        "\n",
        "# change directory to the location of the dataset file CTG.xls\n",
        "\n",
        "#%cd '/workspaces/Tensor-flow-project'\n",
        "\n",
        "# Install xlrd package\n",
        "#%pip install xlrd\n",
        "\n",
        "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
        "#df = pd.read_excel('CTG.xls', sheet_name='Data')\n",
        "\n",
        "# Number of samples\n",
        "#num_samples = df.shape[0]\n",
        "\n",
        "# Number of features\n",
        "#num_features = df.shape[1]\n",
        "\n",
        "# Display these dataset characteristics\n",
        "#print(f\"Number of samples: {num_samples}\")\n",
        "#print(f\"Number of features: {num_features}\")\n",
        "\n",
        "# Display the first few rows of the dataframe to show the structure\n",
        "#print(\"Example data:\")\n",
        "#print(df.head())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KuFzKgflrGF"
      },
      "source": [
        "### A more convenient option is to use the \"fetch_ucirep\" option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skcl0Ds8lrGF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "df = fetch_ucirepo(id=193)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = df.data.features\n",
        "y = df.data.targets\n",
        "\n",
        "# metadata\n",
        "print(df.metadata)\n",
        "\n",
        "# variable information\n",
        "print(df.variables)\n",
        "\n",
        "#print number of samples and features\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "\n",
        "\n",
        "# Display the first few rows of the dataframe to show the structure\n",
        "print(f\"Example data: {X.head()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdHMOqx8lrGF"
      },
      "source": [
        "## Handling Missing Values\n",
        "\n",
        "[Identify any missing values in the dataset, and describe your approach to handle them if there are any. If there are no missing values simply indicate that there are none.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJdH08o9lrGF"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_values_X = X.isnull().sum()\n",
        "missing_values_y = y.isnull().sum()\n",
        "missing_values_X\n",
        "missing_values_y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ild1sTR-lrGG"
      },
      "source": [
        "## Feature Distributions\n",
        "\n",
        "[Plot the distribution of various features and target variables. Comment on the skewness, outliers, or any other observations.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y8IR_Z6lrGG"
      },
      "outputs": [],
      "source": [
        "# Example: Plotting histograms of all numerical features\n",
        "X.hist(figsize=(12, 12))\n",
        "plt.show()\n",
        "\n",
        "y.hist(figsize=(4, 4))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExAPUYv6lrGG"
      },
      "source": [
        "## Possible Biases\n",
        "\n",
        "[Investigate the dataset for any biases that could affect the modelâ€™s performance and fairness (e.g., class imbalance, historical biases).]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM6i--QelrGG"
      },
      "outputs": [],
      "source": [
        "# Example: Checking for class imbalance in a classification problem\n",
        "# sns.countplot(x='target_variable', data=df)\n",
        "\n",
        "# Your code to investigate possible biases goes here\n",
        "\n",
        "#check for class imbalance\n",
        "sns.countplot(x='NSP', data=y) # clear imbalance in the classes\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgeoiWS7lrGH"
      },
      "source": [
        "## Feature Selection and Correlation Analysis\n",
        "\n",
        "[Explore correlations between features and the target variable, as well as among features themselves.]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SelectKBest\n",
        "\n",
        "SelectKBest is used to quickly identify the most relevant features based on their univariate relationship with the target variable. It is particularly helpful for initial feature screening because it ranks features by their statistical significance (e.g., using the ANOVA F-test)."
      ],
      "metadata": {
        "id": "RrMUwm4fJ6wX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuIs-32qlrGH"
      },
      "outputs": [],
      "source": [
        "  # Example: Plotting a heatmap to show feature correlations\n",
        "  correlation_matrix = X.corr()\n",
        "  sns.heatmap(correlation_matrix, annot=True)\n",
        "  plt.show()\n",
        "\n",
        "  # results in unreadable plot due to large number of features\n",
        "  # trying to reduce the number of features by selecting the most important ones\n",
        "\n",
        "  ### Correlation of featurs with the target variable and feature selection\n",
        "\n",
        "  # Feature selection\n",
        "  from sklearn.feature_selection import SelectKBest\n",
        "  from sklearn.feature_selection import f_classif\n",
        "\n",
        "  #apply SelectKBest class to extract top 10 best features --> highest discriminatory power\n",
        "  bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
        "  # Use the second column of y as the target variable, i.e. the NSP column\n",
        "  fit = bestfeatures.fit(X, y.iloc[:, 1])\n",
        "  dfscores = pd.DataFrame(fit.scores_)\n",
        "  dfcolumns = pd.DataFrame(X.columns)\n",
        "\n",
        "  #concat two dataframes for better visualization\n",
        "  featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
        "  featureScores.columns = ['Specs', 'Score']  #naming the dataframe columns\n",
        "  print(featureScores.nlargest(10, 'Score'))  #print 10 best features\n",
        "\n",
        "  # Select the top 10 features\n",
        "  X_selected = X[featureScores.nlargest(10, 'Score')['Specs']]\n",
        "  # selected featurs with highest discriminatory power are : DP  ALTV ASTV  Mean  Mode  Median  AC  Variance  LB  MSTV\n",
        "\n",
        "\n",
        "\n",
        "  ####  correlation of the selected features\n",
        "\n",
        "  # Plot the heatmap of the top 10 features\n",
        "  correlation_matrix = X_selected.corr()\n",
        "  sns.heatmap(correlation_matrix, annot=True)\n",
        "\n",
        "  # RESULT\n",
        "  #  certainly better readability. only very few of the selected features are highly correlated (e.g. >0.8).\n",
        "  # These are : Mean, Mode and Median -->  expecteable. We should use only one of them in the model.\n",
        "\n",
        "  # Drop the Mode and Median columns form the selected features\n",
        "  X_selected = X_selected.drop(['Mode', 'Median'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the importance scores from SelectKBest\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Sort the features by their scores in descending order\n",
        "top_features = featureScores.nlargest(10, 'Score')\n",
        "\n",
        "# Plot\n",
        "plt.barh(top_features['Specs'], top_features['Score'])\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title('Top 10 Features by SelectKBest (f_classif)')\n",
        "plt.gca().invert_yaxis()  # Wichtigste Features oben anzeigen\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aKPqKKNUL0Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Feature Importance\n",
        "\n",
        "Random Forest Feature Importance is added to account for feature interactions and non-linear relationships that SelectKBest might miss. Unlike univariate methods, Random Forest evaluates the role of each feature within the context of the entire dataset. This allows us to capture features that may not be individually significant but contribute strongly when combined with others."
      ],
      "metadata": {
        "id": "4C8hFj5dJ-11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Trainiere einen Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)  # Erzeuge 100 EntscheidungsbÃ¤ume\n",
        "rf.fit(X, y.iloc[:, 1])  # Zielvariable ist die zweite Spalte von y (NSP)\n",
        "\n",
        "# Extrahiere Feature Importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Erstelle einen DataFrame fÃ¼r die Feature-Wichtigkeiten\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Zeige die wichtigsten Features an\n",
        "print(\"Top 10 Features basierend auf Random Forest Feature Importance:\")\n",
        "print(feature_importance_df.head(10))\n",
        "\n",
        "# Visualisiere die Feature-Wichtigkeiten\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance_df['Feature'].head(10), feature_importance_df['Importance'].head(10))\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title('Top 10 Features by Random Forest Importance')\n",
        "plt.gca().invert_yaxis()  # Wichtigste Features oben anzeigen\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdR_eH8NKDcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add MLTV to the list of selected features"
      ],
      "metadata": {
        "id": "_QO456KJT3FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame X_selected_9\n",
        "X_selected_9 = X[featureScores.nlargest(10, 'Score')['Specs']]  # Top 10 features\n",
        "X_selected_9 = X_selected_9.drop(['Mode', 'Median'], axis=1, errors='ignore')  # Drop Mode and Median if present\n",
        "\n",
        "# Add MLTV explicitly\n",
        "if 'MLTV' in X.columns:\n",
        "    X_selected_9 = X_selected_9.assign(MLTV=X['MLTV'])\n",
        "else:\n",
        "    print(\"MLTV is not found in the original dataset.\")\n"
      ],
      "metadata": {
        "id": "P2r7RsscP-fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Short description of the selected features\n",
        "\n",
        "Based on the conducted analyses, the following features have been selected for further modeling and evaluation. These features were chosen using a combination of methods, including SelectKBest and Random Forest Feature Importance, to ensure the inclusion of both univariate significant features and those capturing complex interactions."
      ],
      "metadata": {
        "id": "ffu7HpYHvQnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define selected features, descriptions, and their data types\n",
        "features_summary = {\n",
        "    \"DP\": [\"Prolonged decelerations\", \"Numerical\"],\n",
        "    \"ALTV\": [\"Percentage of time with abnormal long-term variability\", \"Numerical\"],\n",
        "    \"ASTV\": [\"Percentage of time with abnormal short-term variability\", \"Numerical\"],\n",
        "    \"Mean\": [\"Histogram mean\", \"Numerical\"],\n",
        "    \"AC\": [\"Accelerations (SisPorto)\", \"Numerical\"],\n",
        "    \"Variance\": [\"Histogram variance\", \"Numerical\"],\n",
        "    \"LB\": [\"Baseline value (SisPorto)\", \"Numerical\"],\n",
        "    \"MSTV\": [\"Mean value of short-term variability (SisPorto)\", \"Numerical\"],\n",
        "    \"MLTV\": [\"Mean value of long-term variability (SisPorto)\", \"Numerical\"]  # Added MLTV\n",
        "}\n",
        "\n",
        "# Convert to a DataFrame for better readability\n",
        "features_df = pd.DataFrame(\n",
        "    [(key, value[0], value[1]) for key, value in features_summary.items()],\n",
        "    columns=[\"Feature\", \"Description\", \"Data Type\"]\n",
        ")\n",
        "\n",
        "# Set pandas display options to show full width of the table\n",
        "pd.set_option('display.max_colwidth', None)  # Ensure descriptions are fully visible\n",
        "pd.set_option('display.width', 1000)        # Set table width for better display\n",
        "\n",
        "# Save or display the DataFrame\n",
        "print(features_df)"
      ],
      "metadata": {
        "id": "3SiH3VDovYZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distributions of the selected features"
      ],
      "metadata": {
        "id": "fnBO_OPcvDt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract full variable names from features_summary\n",
        "feature_names = {key: value[0] for key, value in features_summary.items()}\n",
        "\n",
        "# Plot histograms with full variable names\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))  # 3x3 grid for 9 features\n",
        "axes = axes.ravel()  # Flatten the axes for easy iteration\n",
        "\n",
        "for idx, column in enumerate(X_selected_9.columns):  # Use X_selected_9 with 9 features\n",
        "    ax = axes[idx]\n",
        "    ax.hist(X_selected_9[column], bins=20, color='skyblue', edgecolor='black')\n",
        "    ax.set_title(feature_names[column], fontsize=10)  # Use full name as title\n",
        "    ax.set_xlabel(\"Value\")\n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "\n",
        "# Hide unused subplots if there are any (unlikely for 9 features in 3x3 grid)\n",
        "for i in range(len(X_selected_9.columns), len(axes)):\n",
        "    axes[i].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i90wz2eIvBCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outlier"
      ],
      "metadata": {
        "id": "h7eB2pmLOHuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Outlier Detection"
      ],
      "metadata": {
        "id": "kD2EqkfcOFb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we analyzed outliers in the dataset using two statistical methods: the IQR (Interquartile Range) and Z-scores.\n",
        "\n",
        "**IQR Method:**\n",
        "\n",
        "We identified variables with symmetric distributions (e.g., Mean and LB) and calculated the lower and upper boundaries based on the IQR.\n",
        "Boxplots were created to visualize these variables, marking the IQR boundaries with vertical dashed lines. Data points outside these boundaries were flagged as potential outliers.\n",
        "\n",
        "**Z-Score Method:**\n",
        "\n",
        "For variables with asymmetrical distributions (e.g., DP, ALTV, AC, Variance, MSTV, ASTV), Z-scores were calculated.\n",
        "Scatter plots were used to visualize the Z-scores, with horizontal dashed lines marking thresholds at Â±3. Data points exceeding these thresholds were considered potential outliers.\n",
        "Both methods allow us to systematically identify and evaluate outliers, which can help improve the quality and reliability of further data analysis."
      ],
      "metadata": {
        "id": "rK-r3wAhOFb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### IQR method and Z-Score method"
      ],
      "metadata": {
        "id": "xA5xNvxdOFb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect outliers based on the IQR method\n",
        "def detect_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)  # First quartile (25%)\n",
        "    Q3 = data.quantile(0.75)  # Third quartile (75%)\n",
        "    IQR = Q3 - Q1  # Interquartile range (IQR)\n",
        "    lower_bound = Q1 - 1.5 * IQR  # Lower boundary\n",
        "    upper_bound = Q3 + 1.5 * IQR  # Upper boundary\n",
        "    return lower_bound, upper_bound  # Return both boundaries\n",
        "\n",
        "\n",
        "# Check for outliers in each feature using IQR\n",
        "outlier_counts_iqr = X_selected_9.apply(detect_outliers_iqr)\n",
        "\n",
        "\n",
        "# Calculate Z-scores for each feature\n",
        "from scipy.stats import zscore\n",
        "z_scores = zscore(X_selected_9, nan_policy='omit')  # Absolute Z-scores\n",
        "z_scores_df = pd.DataFrame(z_scores, columns=X_selected_9.columns)  # Convert to DataFrame\n",
        "outliers_zscore = (z_scores_df.abs() > 3).sum(axis=0)  # Count of outliers where Z > 3\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ywZ-xtY1OFb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data: Number of outliers for each method\n",
        "data = {\n",
        "    \"Feature\": [\"DP\", \"ALTV\", \"ASTV\", \"Mean\", \"AC\", \"Variance\", \"LB\", \"MSTV\", \"MLTV\"],\n",
        "    \"Outliers (IQR)\": [178, 309, 0, 45, 14, 184, 0, 70, 71],\n",
        "    \"Outliers (Z-Score)\": [108, 59, 0, 26, 23, 44, 0, 33, 33],\n",
        "    \"Distribution\": [\n",
        "        \"Highly skewed to the right\",\n",
        "        \"Strongly skewed to the right\",\n",
        "        \"Uniform distribution with peaks\",\n",
        "        \"Symmetrical, approximately normal\",\n",
        "        \"Strongly skewed to the right\",\n",
        "        \"Highly skewed to the right\",\n",
        "        \"Symmetrical and bell-shaped\",\n",
        "        \"Right-skewed distribution\",\n",
        "        \"Moderately skewed to the right\"  #\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "outlier_summary = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(outlier_summary)\n"
      ],
      "metadata": {
        "id": "WF1nwgN-OFb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Visualisation of outliers"
      ],
      "metadata": {
        "id": "IiEyNG8dOFb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables with symmetric distributions suitable for IQR\n",
        "suitable_for_iqr = [\"Mean\", \"LB\", \"MLTV\"]  # MLTV hinzugefÃ¼gt\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, len(suitable_for_iqr), figsize=(15, 5))  # Adjust layout\n",
        "\n",
        "# Iterate over the columns and create a boxplot for each\n",
        "for idx, column in enumerate(suitable_for_iqr):\n",
        "    ax = axes[idx]  # Current axis\n",
        "    lower_bound, upper_bound = detect_outliers_iqr(X_selected_9[column])  # Calculate IQR boundaries\n",
        "\n",
        "    # Boxplot on the current axis\n",
        "    sns.boxplot(\n",
        "        x=X_selected_9[column],\n",
        "        color=\"skyblue\",\n",
        "        showmeans=True,\n",
        "        meanprops={\"marker\": \"D\", \"markerfacecolor\": \"green\", \"markeredgecolor\": \"black\"},\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    # Mark the IQR boundaries with vertical lines\n",
        "    ax.axvline(lower_bound, color=\"red\", linestyle=\"--\", label=\"Lower Boundary (IQR)\")\n",
        "    ax.axvline(upper_bound, color=\"green\", linestyle=\"--\", label=\"Upper Boundary (IQR)\")\n",
        "\n",
        "    # Set title and labels\n",
        "    ax.set_title(f\"{column} (IQR)\")\n",
        "    ax.set_xlabel(\"Value\")\n",
        "    ax.set_ylabel(\"\")  # No y-axis label needed\n",
        "\n",
        "    # Add legend only to the first plot\n",
        "    if idx == 0:\n",
        "        ax.scatter([], [], color=\"green\", marker=\"D\", label=\"Mean\")  # Dummy point for legend\n",
        "        ax.legend()\n",
        "\n",
        "# Adjust layout to prevent overlapping\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "qoNrC05iOFb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "# Calculate Z-scores and convert to a DataFrame\n",
        "z_scores = zscore(X_selected, nan_policy='omit')  # Z-scores as a NumPy array\n",
        "z_scores_df = pd.DataFrame(z_scores, columns=X_selected.columns)  # Convert to DataFrame\n",
        "\n",
        "# Variables with asymmetrical distribution\n",
        "asymmetrical_features = [\"DP\", \"ALTV\", \"AC\", \"Variance\", \"MSTV\", \"ASTV\"]\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, len(asymmetrical_features), figsize=(20, 5))  # Wider layout for multiple plots\n",
        "\n",
        "for idx, column in enumerate(asymmetrical_features):\n",
        "    ax = axes[idx]  # Current axis\n",
        "    feature_z_scores = z_scores_df[column]  # Z-scores for the current variable\n",
        "\n",
        "    # Scatter plot for Z-scores\n",
        "    ax.scatter(range(len(feature_z_scores)), feature_z_scores, alpha=0.5, label=\"Data Points\")\n",
        "\n",
        "    # Horizontal lines for Z-score thresholds\n",
        "    ax.axhline(3, color=\"red\", linestyle=\"--\", label=\"Z = +3 (Upper Limit)\")\n",
        "    ax.axhline(-3, color=\"red\", linestyle=\"--\", label=\"Z = -3 (Lower Limit)\")\n",
        "\n",
        "    # Set title and labels\n",
        "    ax.set_title(f\"{column} (Z-Score)\")\n",
        "    ax.set_xlabel(\"Index\")\n",
        "    ax.set_ylabel(\"Z-Score\")\n",
        "\n",
        "    # Display legend only in the first plot\n",
        "    if idx == 0:\n",
        "        ax.legend()\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PyDr5c69OFb6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}