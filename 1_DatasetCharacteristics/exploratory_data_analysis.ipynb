{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY8z4UO5lrGB"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "## Table of Contents\n",
        "1. [Dataset Overview](#dataset-overview)\n",
        "2. [Handling Missing Values](#handling-missing-values)\n",
        "3. [Feature Distributions](#feature-distributions)\n",
        "4. [Possible Biases](#possible-biases)\n",
        "5. [Correlations](#correlations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhLMkoh8lrGD"
      },
      "source": [
        ". [Correlations](#correlations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srHznX5SlrGD"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%pip install ucimlrepo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OftNOC-alrGE"
      },
      "source": [
        "## Dataset Overview\n",
        "\n",
        "[Provide a high-level overview of the dataset. This should include the source of the dataset, the number of samples, the number of features, and example showing the structure of the dataset.]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GpG8aW-lrGE"
      },
      "source": [
        "## Attention: currently commented out since there is better way as shown in the next code snippet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vCxzauRlrGE"
      },
      "outputs": [],
      "source": [
        "# comment out the following lines\n",
        "\n",
        "\n",
        "# change directory to the location of the dataset file CTG.xls\n",
        "\n",
        "#%cd '/workspaces/Tensor-flow-project'\n",
        "\n",
        "# Install xlrd package\n",
        "#%pip install xlrd\n",
        "\n",
        "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
        "#df = pd.read_excel('CTG.xls', sheet_name='Data')\n",
        "\n",
        "# Number of samples\n",
        "#num_samples = df.shape[0]\n",
        "\n",
        "# Number of features\n",
        "#num_features = df.shape[1]\n",
        "\n",
        "# Display these dataset characteristics\n",
        "#print(f\"Number of samples: {num_samples}\")\n",
        "#print(f\"Number of features: {num_features}\")\n",
        "\n",
        "# Display the first few rows of the dataframe to show the structure\n",
        "#print(\"Example data:\")\n",
        "#print(df.head())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KuFzKgflrGF"
      },
      "source": [
        "## A more convenient option is to use the \"fetch_ucirep\" option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skcl0Ds8lrGF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "df = fetch_ucirepo(id=193)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = df.data.features\n",
        "y = df.data.targets\n",
        "\n",
        "# metadata\n",
        "print(df.metadata)\n",
        "\n",
        "# variable information\n",
        "print(df.variables)\n",
        "\n",
        "#print number of samples and features\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "\n",
        "\n",
        "# Display the first few rows of the dataframe to show the structure\n",
        "print(f\"Example data: {X.head()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdHMOqx8lrGF"
      },
      "source": [
        "## Handling Missing Values\n",
        "\n",
        "[Identify any missing values in the dataset, and describe your approach to handle them if there are any. If there are no missing values simply indicate that there are none.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJdH08o9lrGF"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_values_X = X.isnull().sum()\n",
        "missing_values_y = y.isnull().sum()\n",
        "missing_values_X\n",
        "missing_values_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlkE5oPklrGG"
      },
      "outputs": [],
      "source": [
        "# Handling missing values\n",
        "# Example: Replacing NaN values with the mean value of the column\n",
        "# df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Your code for handling missing values goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ild1sTR-lrGG"
      },
      "source": [
        "## Feature Distributions\n",
        "\n",
        "[Plot the distribution of various features and target variables. Comment on the skewness, outliers, or any other observations.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y8IR_Z6lrGG"
      },
      "outputs": [],
      "source": [
        "# Example: Plotting histograms of all numerical features\n",
        "X.hist(figsize=(12, 12))\n",
        "plt.show()\n",
        "\n",
        "y.hist(figsize=(4, 4))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u90XYXVHt4Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExAPUYv6lrGG"
      },
      "source": [
        "## Possible Biases\n",
        "\n",
        "[Investigate the dataset for any biases that could affect the model’s performance and fairness (e.g., class imbalance, historical biases).]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM6i--QelrGG"
      },
      "outputs": [],
      "source": [
        "# Example: Checking for class imbalance in a classification problem\n",
        "# sns.countplot(x='target_variable', data=df)\n",
        "\n",
        "# Your code to investigate possible biases goes here\n",
        "\n",
        "#check for class imbalance\n",
        "sns.countplot(x='NSP', data=y) # clear imbalance in the classes\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgeoiWS7lrGH"
      },
      "source": [
        "## Feature Selection and Correlation Analysis\n",
        "\n",
        "[Explore correlations between features and the target variable, as well as among features themselves.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuIs-32qlrGH"
      },
      "outputs": [],
      "source": [
        "# Example: Plotting a heatmap to show feature correlations\n",
        "correlation_matrix = X.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "plt.show()\n",
        "\n",
        "# results in unreadable plot due to large number of features\n",
        "# trying to reduce the number of features by selecting the most important ones\n",
        "\n",
        "### Correlation of featurs with the target variable and feature selection\n",
        "\n",
        "# Feature selection\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "#apply SelectKBest class to extract top 10 best features --> highest discriminatory power\n",
        "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
        "# Use the second column of y as the target variable, i.e. the NSP column\n",
        "fit = bestfeatures.fit(X, y.iloc[:, 1])\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "\n",
        "#concat two dataframes for better visualization\n",
        "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
        "featureScores.columns = ['Specs', 'Score']  #naming the dataframe columns\n",
        "print(featureScores.nlargest(10, 'Score'))  #print 10 best features\n",
        "\n",
        "# Select the top 10 features\n",
        "X_selected = X[featureScores.nlargest(10, 'Score')['Specs']]\n",
        "# selected featurs with highest discriminatory power are : DP  ALTV ASTV  Mean  Mode  Median  AC  Variance  LB  MSTV\n",
        "\n",
        "\n",
        "\n",
        "####  correlation of the selected features\n",
        "\n",
        "# Plot the heatmap of the top 10 features\n",
        "correlation_matrix = X_selected.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "\n",
        "# RESULT\n",
        "#  certainly better readability. only very few of the selected features are highly correlated (e.g. >0.8).\n",
        "# These are : Mean, Mode and Median -->  expecteable. We should use only one of them in the model.\n",
        "\n",
        "# Drop the Mode and Median columns form the selected features\n",
        "X_selected = X_selected.drop(['Mode', 'Median'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BYsDmDsapQP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v1yK13T-u4dw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Short description of the selected features"
      ],
      "metadata": {
        "id": "ffu7HpYHvQnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define selected features, descriptions, and their data types\n",
        "features_summary = {\n",
        "    \"DP\": [\"Prolonged decelerations\", \"Numerical\"],\n",
        "    \"ALTV\": [\"Percentage of time with abnormal long-term variability\", \"Numerical\"],\n",
        "    \"ASTV\": [\"Percentage of time with abnormal short-term variability\", \"Numerical\"],\n",
        "    \"Mean\": [\"Histogram mean\", \"Numerical\"],\n",
        "    \"AC\": [\"Accelerations (SisPorto)\", \"Numerical\"],\n",
        "    \"Variance\": [\"Histogram variance\", \"Numerical\"],\n",
        "    \"LB\": [\"Baseline value (SisPorto)\", \"Numerical\"],\n",
        "    \"MSTV\": [\"Mean value of short-term variability (SisPorto)\", \"Numerical\"]\n",
        "}\n",
        "\n",
        "# Convert to a DataFrame for better readability\n",
        "features_df = pd.DataFrame(\n",
        "    [(key, value[0], value[1]) for key, value in features_summary.items()],\n",
        "    columns=[\"Feature\", \"Description\", \"Data Type\"]\n",
        ")\n",
        "\n",
        "# Set pandas display options to show full width of the table\n",
        "pd.set_option('display.max_colwidth', None)  # Ensure descriptions are fully visible\n",
        "pd.set_option('display.width', 1000)        # Set table width for better display\n",
        "\n",
        "# Save or display the DataFrame\n",
        "print(features_df)"
      ],
      "metadata": {
        "id": "3SiH3VDovYZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distributions of the selected features"
      ],
      "metadata": {
        "id": "fnBO_OPcvDt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define full variable names for the selected features\n",
        "feature_names = {\n",
        "    \"DP\": \"Prolonged Decelerations\",\n",
        "    \"ALTV\": \"Percentage of Time with Abnormal Long-Term Variability\",\n",
        "    \"ASTV\": \"Percentage of Time with Abnormal Short-Term Variability\",\n",
        "    \"Mean\": \"Histogram Mean\",\n",
        "    \"AC\": \"Accelerations (SisPorto)\",\n",
        "    \"Variance\": \"Histogram Variance\",\n",
        "    \"LB\": \"Baseline Value (SisPorto)\",\n",
        "    \"MSTV\": \"Mean Value of Short-Term Variability (SisPorto)\"\n",
        "}\n",
        "\n",
        "# Plot histograms with full variable names\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))  # Adjust layout as needed\n",
        "axes = axes.ravel()  # Flatten the axes for easy iteration\n",
        "\n",
        "for idx, column in enumerate(X_selected.columns):\n",
        "    ax = axes[idx]\n",
        "    ax.hist(X_selected[column], bins=20, color='skyblue', edgecolor='black')\n",
        "    ax.set_title(feature_names[column], fontsize=10)  # Use full name as title\n",
        "    ax.set_xlabel(\"Value\")\n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "\n",
        "# Hide unused subplots if the number of features is less than the grid size\n",
        "for i in range(len(X_selected.columns), len(axes)):\n",
        "    axes[i].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "i90wz2eIvBCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlier"
      ],
      "metadata": {
        "id": "kRIlaDPL97Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outlier Detection"
      ],
      "metadata": {
        "id": "y5qhyJZGsGdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we analyzed outliers in the dataset using two statistical methods: the IQR (Interquartile Range) and Z-scores.\n",
        "\n",
        "**IQR Method:**\n",
        "\n",
        "We identified variables with symmetric distributions (e.g., Mean and LB) and calculated the lower and upper boundaries based on the IQR.\n",
        "Boxplots were created to visualize these variables, marking the IQR boundaries with vertical dashed lines. Data points outside these boundaries were flagged as potential outliers.\n",
        "\n",
        "**Z-Score Method:**\n",
        "\n",
        "For variables with asymmetrical distributions (e.g., DP, ALTV, AC, Variance, MSTV, ASTV), Z-scores were calculated.\n",
        "Scatter plots were used to visualize the Z-scores, with horizontal dashed lines marking thresholds at ±3. Data points exceeding these thresholds were considered potential outliers.\n",
        "Both methods allow us to systematically identify and evaluate outliers, which can help improve the quality and reliability of further data analysis."
      ],
      "metadata": {
        "id": "v9iaLbDi-aSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IQR method and Z-Score method"
      ],
      "metadata": {
        "id": "WeW0ZsOysJn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect outliers based on the IQR method\n",
        "def detect_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)  # First quartile (25%)\n",
        "    Q3 = data.quantile(0.75)  # Third quartile (75%)\n",
        "    IQR = Q3 - Q1  # Interquartile range\n",
        "    lower_bound = Q1 - 1.5 * IQR  # Lower boundary for outliers\n",
        "    upper_bound = Q3 + 1.5 * IQR  # Upper boundary for outliers\n",
        "    outliers = ((data < lower_bound) | (data > upper_bound)).sum()  # Count of outliers\n",
        "    return outliers\n",
        "\n",
        "# Check for outliers in each feature\n",
        "outlier_counts = X_selected.apply(detect_outliers_iqr)\n",
        "print(\"Number of outliers per feature (IQR):\")\n",
        "print(outlier_counts)\n",
        "\n",
        "# Calculate Z-scores for each feature\n",
        "z_scores = np.abs(zscore(X_selected))  # Absolute Z-scores\n",
        "outliers_zscore = (z_scores > 3).sum(axis=0)  # Count of outliers where Z > 3\n",
        "print(\"Number of outliers per feature (Z-Score):\")\n",
        "print(outliers_zscore)\n",
        "\n"
      ],
      "metadata": {
        "id": "utuSBfLSr3rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data: Number of outliers for each method\n",
        "data = {\n",
        "    \"Feature\": [\"DP\", \"ALTV\", \"ASTV\", \"Mean\", \"AC\", \"Variance\", \"LB\", \"MSTV\"],\n",
        "    \"Outliers (IQR)\": [178, 309, 0, 45, 14, 184, 0, 70],\n",
        "    \"Outliers (Z-Score)\": [108, 59, 0, 26, 23, 44, 0, 33],\n",
        "    \"Distribution\": [\n",
        "        \"Highly skewed to the right\",\n",
        "        \"Strongly skewed to the right\",\n",
        "        \"Uniform distribution with peaks\",\n",
        "        \"Symmetrical, approximately normal\",\n",
        "        \"Strongly skewed to the right\",\n",
        "        \"Highly skewed to the right\",\n",
        "        \"Symmetrical and bell-shaped\",\n",
        "        \"Right-skewed distribution\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "outlier_summary = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(outlier_summary)"
      ],
      "metadata": {
        "id": "bmc-5ck9xLPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisation of outliers"
      ],
      "metadata": {
        "id": "YGMHoX8q7tu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate IQR thresholds\n",
        "def detect_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)  # First quartile (25%)\n",
        "    Q3 = data.quantile(0.75)  # Third quartile (75%)\n",
        "    IQR = Q3 - Q1  # Interquartile range (IQR)\n",
        "    lower_bound = Q1 - 1.5 * IQR  # Lower boundary\n",
        "    upper_bound = Q3 + 1.5 * IQR  # Upper boundary\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Variables with symmetric distributions suitable for IQR\n",
        "suitable_for_iqr = [\"Mean\", \"LB\"]\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, len(suitable_for_iqr), figsize=(12, 4))  # Smaller, side-by-side plots\n",
        "\n",
        "# Iterate over the columns and create a boxplot for each\n",
        "for idx, column in enumerate(suitable_for_iqr):\n",
        "    ax = axes[idx]  # Current axis\n",
        "    lower_bound, upper_bound = detect_outliers_iqr(X_selected[column])  # Calculate IQR boundaries\n",
        "\n",
        "    # Boxplot on the current axis\n",
        "    sns.boxplot(\n",
        "        x=X_selected[column],\n",
        "        color=\"skyblue\",\n",
        "        showmeans=True,\n",
        "        meanprops={\"marker\": \"D\", \"markerfacecolor\": \"green\", \"markeredgecolor\": \"black\"},\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    # Mark the IQR boundaries with vertical lines\n",
        "    ax.axvline(lower_bound, color=\"red\", linestyle=\"--\", label=\"Lower Boundary (IQR)\")\n",
        "    ax.axvline(upper_bound, color=\"green\", linestyle=\"--\", label=\"Upper Boundary (IQR)\")\n",
        "\n",
        "    # Set title and labels\n",
        "    ax.set_title(f\"{column} (IQR)\")\n",
        "    ax.set_xlabel(\"Value\")\n",
        "    ax.set_ylabel(\"\")  # No y-axis label needed\n",
        "\n",
        "    # Add legend only to the first plot\n",
        "    if idx == 0:\n",
        "        ax.scatter([], [], color=\"green\", marker=\"D\", label=\"Mean\")  # Dummy point for legend\n",
        "        ax.legend()\n",
        "\n",
        "# Adjust layout to prevent overlapping\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwGy64j2zbUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "# Calculate Z-scores and convert to a DataFrame\n",
        "z_scores = zscore(X_selected, nan_policy='omit')  # Z-scores as a NumPy array\n",
        "z_scores_df = pd.DataFrame(z_scores, columns=X_selected.columns)  # Convert to DataFrame\n",
        "\n",
        "# Variables with asymmetrical distribution\n",
        "asymmetrical_features = [\"DP\", \"ALTV\", \"AC\", \"Variance\", \"MSTV\", \"ASTV\"]\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, len(asymmetrical_features), figsize=(20, 5))  # Wider layout for multiple plots\n",
        "\n",
        "for idx, column in enumerate(asymmetrical_features):\n",
        "    ax = axes[idx]  # Current axis\n",
        "    feature_z_scores = z_scores_df[column]  # Z-scores for the current variable\n",
        "\n",
        "    # Scatter plot for Z-scores\n",
        "    ax.scatter(range(len(feature_z_scores)), feature_z_scores, alpha=0.5, label=\"Data Points\")\n",
        "\n",
        "    # Horizontal lines for Z-score thresholds\n",
        "    ax.axhline(3, color=\"red\", linestyle=\"--\", label=\"Z = +3 (Upper Limit)\")\n",
        "    ax.axhline(-3, color=\"red\", linestyle=\"--\", label=\"Z = -3 (Lower Limit)\")\n",
        "\n",
        "    # Set title and labels\n",
        "    ax.set_title(f\"{column} (Z-Score)\")\n",
        "    ax.set_xlabel(\"Index\")\n",
        "    ax.set_ylabel(\"Z-Score\")\n",
        "\n",
        "    # Display legend only in the first plot\n",
        "    if idx == 0:\n",
        "        ax.legend()\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "U_LZNc3u2HK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with outliers"
      ],
      "metadata": {
        "id": "iLYXzEpp-E6X"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}